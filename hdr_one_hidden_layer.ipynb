{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#loading training and test data\n",
    "train_data=pd.read_csv(\"mnist_train.csv\", header=None)\n",
    "test_data=pd.read_csv(\"mnist_test.csv\", header=None)\n",
    "\n",
    "#modifying loaded data to desired form\n",
    "y_desired=train_data.iloc[:, [0]]\n",
    "x_train=train_data.iloc[:, 1: ]/255\n",
    "y_test=test_data.iloc[:, [0]]\n",
    "x_test=test_data.iloc[:, 1:]/255\n",
    "\n",
    "for i in range(1,6):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.imshow(np.array(x_train)[:, [i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train=x_train.shape[0]\n",
    "m_test=x_test.shape[0]\n",
    "n=x_train.shape[1]\n",
    "\n",
    "y_train = np.zeros((m_train, 10))\n",
    "for i in range (0, m_train):\n",
    "    y_train[i][y_desired.iloc[i]]=1.0\n",
    "y_testt= np.zeros((m_test, 10))\n",
    "for i in range (0, m_test):\n",
    "    y_testt[i][y_test.iloc[i]]=1.0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s\n",
    "def layer_sizes(X, Y):\n",
    "    n_x = X.shape[1] \n",
    "    n_h = 64\n",
    "    n_y = Y.shape[1] \n",
    "    \n",
    "    return (n_x, n_h, n_y)\n",
    "\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((1,n_h))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((1, n_y))\n",
    "    parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    #propagate_forwrd\n",
    "    Z1 = np.dot(X, W1.T)+b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(A1, W2.T)+b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    m = Y.shape[0]\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    \n",
    "    logprobs = np.multiply(np.log(A2),Y)+np.multiply(np.log(1-A2),(1-Y))\n",
    "    cost = (-1/m)*np.sum(logprobs)+(1/m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    m = X.shape[1]\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    \n",
    "    #backprop\n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1/m)*np.dot(dZ2.T, A1)\n",
    "    db2 = (1/m)*np.sum(dZ2, axis=0, keepdims=True)\n",
    "    dZ1 = np.dot(dZ2, W2)*(1-np.power(A1,2))\n",
    "    dW1 = (1/m)*np.dot(dZ1.T, X)\n",
    "    db1 = (1/m)*np.sum(dZ1, axis=0,keepdims=True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    \n",
    "    W1 = W1-learning_rate*dW1\n",
    "    b1 = b1-learning_rate*db1\n",
    "    W2 = W2-learning_rate*dW2\n",
    "    b2 = b2-learning_rate*db2\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X, Y, n_h, num_iterations, print_cost=False):\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    m = X.shape[0]\n",
    "    parameters = initialize_parameters(n_x,n_h,n_y)\n",
    "    \n",
    "    #gradient descent\n",
    "    for i in range(0, num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        \n",
    "        # Cost function\n",
    "        cost = compute_cost(A2, Y, parameters)\n",
    " \n",
    "        # Backpropagation\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    " \n",
    "        # parameter update\n",
    "        parameters = update_parameters(parameters, grads, learning_rate = 0.01)\n",
    "        \n",
    "        if print_cost and i % 20 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    \n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = A2>0.5\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 6.926005\n",
      "Cost after iteration 20: 3.144813\n",
      "Cost after iteration 40: 1.328105\n",
      "Cost after iteration 60: 0.890047\n",
      "Cost after iteration 80: 0.792179\n",
      "Cost after iteration 100: 0.626328\n",
      "Cost after iteration 120: 0.572862\n",
      "Cost after iteration 140: 0.537723\n",
      "Cost after iteration 160: 0.510102\n",
      "Cost after iteration 180: 0.487222\n",
      "Cost after iteration 200: 0.467688\n",
      "Cost after iteration 220: 0.450678\n",
      "Cost after iteration 240: 0.435651\n",
      "Cost after iteration 260: 0.422226\n",
      "Cost after iteration 280: 0.410114\n",
      "train accuracy: 98.765 %\n",
      "test accuracy: 98.803 %\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(x_train, y_train, n_h = 64, num_iterations =300 , print_cost=True)\n",
    "predictions_train = predict(parameters, x_train)\n",
    "predictions_test=predict(parameters, x_test)\n",
    "\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(predictions_train-y_train)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(predictions_test-y_testt)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
